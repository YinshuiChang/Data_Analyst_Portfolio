{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8884bd-2893-4a2c-9d88-123adb2ba252",
   "metadata": {},
   "source": [
    "# Variational Convolutional Autoencoder (VCAE)\n",
    "A Variational Convolutional Autoencoder (VCAE) is a type of generative model and a specific kind of autoencoder that incorporates principles from variational inference to model the underlying distribution of data. VAEs are designed to generate new data samples that are similar to the training data by learning a probabilistic mapping between the input data and a latent space.\n",
    "Key Concepts:\n",
    "* **Probabilistic Approach:** VCAEs are generative models that assume the data is generated by some latent variables. They learn to model the distribution of the data and generate new samples from this distribution.\n",
    "* **Latent Space Regularization:** VCAEs impose a prior distribution (usually Gaussian) on the latent space and regularize it using the Kullback-Leibler (KL) divergence, encouraging the latent variables to follow this distribution.\n",
    "* **Reparameterization Trick:** To make the model differentiable and suitable for gradient-based optimization, the reparameterization trick is used, where the latent variables are expressed as a deterministic function of a parameterized mean and standard deviation, plus some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b18720-8b02-4a97-aacb-69027c101638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "ae_version = \"v07\"\n",
    "ae_layers = 1\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6104916-ce08-4f5e-add7-9d7db1e827b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.9\n",
      "numpy: 1.23.5\n",
      "tensorflow: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import sys\n",
    "print('Python: ' + python_version()) # Python: 3.10.9\n",
    "print('numpy: ' + np.__version__) # numpy: 1.23.5\n",
    "print ('tensorflow: ' + sys.modules[\"tensorflow\"].__version__) # tensorflow: 2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4150507b-e967-49ad-97b6-6e45469b39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_AE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CNN_AE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(182, 362, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=8, kernel_size=4, strides=2, activation='relu', padding='valid'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=6*12*64, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(6, 12, 64)),\n",
    "\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Cropping2D(cropping=((0, 0), (0, 1))),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Cropping2D(cropping=((0, 1), (0, 1))),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Cropping2D(cropping=((0, 1), (0, 0))),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=16, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=8, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=1, kernel_size=4, strides=1, padding='same'),\n",
    "        ]\n",
    "        )\n",
    "    \n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        logits = self.decoder(z)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4fe75c-4aaf-4113-b800-2d0e28555cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    #Reconstruction loss\n",
    "    reconstruction_loss = tf.keras.backend.mean(tf.math.square(x_logit - x[:,1:181,1:361,:]), axis=[1, 2, 3])\n",
    "    #KL div loss\n",
    "    kl_loss = - 0.5 * tf.keras.backend.mean(1 + logvar - tf.keras.backend.square(mean) - tf.keras.backend.exp(logvar), axis=-1)\n",
    "    elbo = tf.keras.backend.mean(reconstruction_loss + kl_loss)\n",
    "    return elbo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6aea6e9-f03e-4078-931c-c1f3f4b1f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24fe5e0d-0bd7-4fdc-b2e1-40f905d69806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_AE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ce5fbc-d25e-430e-b7de-1dd297a870fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 90, 180, 8)        136       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 45, 90, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 23, 45, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 23, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 12, 64)         36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 27654     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,022\n",
      "Trainable params: 89,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 4608)              18432     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 6, 12, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 12, 24, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " cropping2d (Cropping2D)     (None, 12, 23, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 24, 46, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " cropping2d_1 (Cropping2D)   (None, 23, 45, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 46, 90, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " cropping2d_2 (Cropping2D)   (None, 45, 90, 32)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 90, 180, 16)      4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 180, 360, 8)      1160      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 180, 360, 1)       129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,665\n",
      "Trainable params: 116,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.encoder.summary()\n",
    "model.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae7dc4f-c68f-4165-97ab-8208c00b8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube_precip = np.load(\"../data/WaterPrecip_datacube_CAE_single.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76abdd9-83e5-424d-adee-c2fc6bad2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datacube_precip = datacube_precip/datacube_precip.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5242343-f3b5-4b80-882d-0bd0f6ec1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1000\n",
    "train_size = datacube_precip.shape[0] - test_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878f8ba6-8699-4fb6-8635-89dc83fbd379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(datacube_precip)\n",
    "                 .shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(datacube_precip)\n",
    "                .shuffle(test_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0968757-3f4b-4074-a0dc-0c722ccdafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777f7ab9-3aa4-4cf3-8747-a634c19d2ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test set ELBO: 24.562021255493164, time elapse for current epoch: 91.60698962211609\n",
      "Epoch: 2, Test set ELBO: 24.37751579284668, time elapse for current epoch: 94.14610838890076\n",
      "Epoch: 3, Test set ELBO: 24.285104751586914, time elapse for current epoch: 95.56970191001892\n",
      "Epoch: 4, Test set ELBO: 24.25105094909668, time elapse for current epoch: 99.46296954154968\n",
      "Epoch: 5, Test set ELBO: 24.211315155029297, time elapse for current epoch: 109.63563394546509\n",
      "Epoch: 6, Test set ELBO: 24.207128524780273, time elapse for current epoch: 105.78567337989807\n",
      "Epoch: 7, Test set ELBO: 24.164278030395508, time elapse for current epoch: 104.64545631408691\n",
      "Epoch: 8, Test set ELBO: 24.14128875732422, time elapse for current epoch: 94.29784941673279\n",
      "Epoch: 9, Test set ELBO: 24.13054847717285, time elapse for current epoch: 105.45315074920654\n",
      "Epoch: 10, Test set ELBO: 24.140180587768555, time elapse for current epoch: 99.57289528846741\n",
      "Epoch: 11, Test set ELBO: 24.149242401123047, time elapse for current epoch: 96.36579179763794\n",
      "Epoch: 12, Test set ELBO: 24.121335983276367, time elapse for current epoch: 101.20970916748047\n",
      "Epoch: 13, Test set ELBO: 24.109106063842773, time elapse for current epoch: 96.33301568031311\n",
      "Epoch: 14, Test set ELBO: 24.107093811035156, time elapse for current epoch: 99.88086652755737\n",
      "Epoch: 15, Test set ELBO: 24.104944229125977, time elapse for current epoch: 91.77063202857971\n",
      "Epoch: 16, Test set ELBO: 24.116085052490234, time elapse for current epoch: 105.0449857711792\n",
      "Epoch: 17, Test set ELBO: 24.15852165222168, time elapse for current epoch: 101.69908714294434\n",
      "Epoch: 18, Test set ELBO: 24.113079071044922, time elapse for current epoch: 100.32362461090088\n",
      "Epoch: 19, Test set ELBO: 24.114723205566406, time elapse for current epoch: 98.37279081344604\n",
      "Epoch: 20, Test set ELBO: 24.08799934387207, time elapse for current epoch: 105.48675322532654\n",
      "Epoch: 21, Test set ELBO: 24.09614372253418, time elapse for current epoch: 102.30379962921143\n",
      "Epoch: 22, Test set ELBO: 24.064912796020508, time elapse for current epoch: 100.81617474555969\n",
      "Epoch: 23, Test set ELBO: 24.0855770111084, time elapse for current epoch: 118.03442358970642\n",
      "Epoch: 24, Test set ELBO: 24.068498611450195, time elapse for current epoch: 131.4418911933899\n",
      "Epoch: 25, Test set ELBO: 24.088653564453125, time elapse for current epoch: 140.9381103515625\n",
      "Epoch: 26, Test set ELBO: 24.06378936767578, time elapse for current epoch: 131.42471981048584\n",
      "Epoch: 27, Test set ELBO: 24.073667526245117, time elapse for current epoch: 131.00382924079895\n",
      "Epoch: 28, Test set ELBO: 24.06560516357422, time elapse for current epoch: 140.92030572891235\n",
      "Epoch: 29, Test set ELBO: 24.055856704711914, time elapse for current epoch: 142.54474258422852\n",
      "Epoch: 30, Test set ELBO: 24.052885055541992, time elapse for current epoch: 139.39141654968262\n",
      "Epoch: 31, Test set ELBO: 24.069610595703125, time elapse for current epoch: 139.56718039512634\n",
      "Epoch: 32, Test set ELBO: 24.04847526550293, time elapse for current epoch: 145.22256135940552\n",
      "Epoch: 33, Test set ELBO: 24.046863555908203, time elapse for current epoch: 153.19884967803955\n",
      "Epoch: 34, Test set ELBO: 24.049375534057617, time elapse for current epoch: 230.39286184310913\n",
      "Epoch: 35, Test set ELBO: 24.04096794128418, time elapse for current epoch: 121.97003126144409\n",
      "Epoch: 36, Test set ELBO: 24.049306869506836, time elapse for current epoch: 153.76032757759094\n",
      "Epoch: 37, Test set ELBO: 24.03529930114746, time elapse for current epoch: 189.31985664367676\n",
      "Epoch: 38, Test set ELBO: 24.05203628540039, time elapse for current epoch: 186.76102447509766\n",
      "Epoch: 39, Test set ELBO: 24.037405014038086, time elapse for current epoch: 189.68099308013916\n",
      "Epoch: 40, Test set ELBO: 24.04038429260254, time elapse for current epoch: 190.82762813568115\n",
      "Epoch: 41, Test set ELBO: 24.030458450317383, time elapse for current epoch: 198.4995822906494\n",
      "Epoch: 42, Test set ELBO: 24.039039611816406, time elapse for current epoch: 193.3842875957489\n",
      "Epoch: 43, Test set ELBO: 24.04229736328125, time elapse for current epoch: 137.51245832443237\n",
      "Epoch: 44, Test set ELBO: 24.045063018798828, time elapse for current epoch: 102.00470495223999\n",
      "Epoch: 45, Test set ELBO: 24.03397560119629, time elapse for current epoch: 104.3156807422638\n",
      "Epoch: 46, Test set ELBO: 24.030193328857422, time elapse for current epoch: 99.60456609725952\n",
      "Epoch: 47, Test set ELBO: 24.029388427734375, time elapse for current epoch: 119.94812273979187\n",
      "Epoch: 48, Test set ELBO: 24.033891677856445, time elapse for current epoch: 99.11129331588745\n",
      "Epoch: 49, Test set ELBO: 24.02635383605957, time elapse for current epoch: 104.3193929195404\n",
      "Epoch: 50, Test set ELBO: 24.043685913085938, time elapse for current epoch: 113.32740592956543\n",
      "Epoch: 51, Test set ELBO: 24.017894744873047, time elapse for current epoch: 96.35707974433899\n",
      "Epoch: 52, Test set ELBO: 24.01854133605957, time elapse for current epoch: 96.1017735004425\n",
      "Epoch: 53, Test set ELBO: 24.018531799316406, time elapse for current epoch: 98.99046587944031\n",
      "Epoch: 54, Test set ELBO: 24.027416229248047, time elapse for current epoch: 99.84263920783997\n",
      "Epoch: 55, Test set ELBO: 24.023435592651367, time elapse for current epoch: 102.13663744926453\n",
      "Epoch: 56, Test set ELBO: 24.03667449951172, time elapse for current epoch: 101.65960693359375\n",
      "Epoch: 57, Test set ELBO: 24.011137008666992, time elapse for current epoch: 102.65002965927124\n",
      "Epoch: 58, Test set ELBO: 24.011484146118164, time elapse for current epoch: 97.88980913162231\n",
      "Epoch: 59, Test set ELBO: 24.00798225402832, time elapse for current epoch: 105.89601993560791\n",
      "Epoch: 60, Test set ELBO: 24.01043701171875, time elapse for current epoch: 99.88711404800415\n",
      "Epoch: 61, Test set ELBO: 24.01454734802246, time elapse for current epoch: 101.56853556632996\n",
      "Epoch: 62, Test set ELBO: 24.012746810913086, time elapse for current epoch: 106.15902185440063\n",
      "Epoch: 63, Test set ELBO: 24.017818450927734, time elapse for current epoch: 100.54764771461487\n",
      "Epoch: 64, Test set ELBO: 24.01236343383789, time elapse for current epoch: 101.03486156463623\n",
      "Epoch: 65, Test set ELBO: 24.01264762878418, time elapse for current epoch: 107.69930291175842\n",
      "Epoch: 66, Test set ELBO: 24.004831314086914, time elapse for current epoch: 101.89242744445801\n",
      "Epoch: 67, Test set ELBO: 23.992786407470703, time elapse for current epoch: 105.46064710617065\n",
      "Epoch: 68, Test set ELBO: 24.00563621520996, time elapse for current epoch: 100.31541347503662\n",
      "Epoch: 69, Test set ELBO: 24.000959396362305, time elapse for current epoch: 102.37096619606018\n",
      "Epoch: 70, Test set ELBO: 23.995628356933594, time elapse for current epoch: 103.40570974349976\n",
      "Epoch: 71, Test set ELBO: 23.9967098236084, time elapse for current epoch: 98.13454866409302\n",
      "Epoch: 72, Test set ELBO: 24.017377853393555, time elapse for current epoch: 97.88776278495789\n",
      "Epoch: 73, Test set ELBO: 24.009183883666992, time elapse for current epoch: 100.37787628173828\n",
      "Epoch: 74, Test set ELBO: 24.014297485351562, time elapse for current epoch: 99.98318338394165\n",
      "Epoch: 75, Test set ELBO: 24.003870010375977, time elapse for current epoch: 99.31154775619507\n",
      "Epoch: 76, Test set ELBO: 24.005155563354492, time elapse for current epoch: 98.80292344093323\n",
      "Epoch: 77, Test set ELBO: 23.991657257080078, time elapse for current epoch: 99.666339635849\n",
      "Epoch: 78, Test set ELBO: 23.997499465942383, time elapse for current epoch: 95.80575513839722\n",
      "Epoch: 79, Test set ELBO: 23.997482299804688, time elapse for current epoch: 98.7919716835022\n",
      "Epoch: 80, Test set ELBO: 23.99422264099121, time elapse for current epoch: 105.08337044715881\n",
      "Epoch: 81, Test set ELBO: 24.029821395874023, time elapse for current epoch: 101.06645941734314\n",
      "Epoch: 82, Test set ELBO: 23.997756958007812, time elapse for current epoch: 98.23334455490112\n",
      "Epoch: 83, Test set ELBO: 23.994068145751953, time elapse for current epoch: 100.56748747825623\n",
      "Epoch: 84, Test set ELBO: 23.98985481262207, time elapse for current epoch: 104.2362322807312\n",
      "Epoch: 85, Test set ELBO: 23.996522903442383, time elapse for current epoch: 97.527108669281\n",
      "Epoch: 86, Test set ELBO: 24.036457061767578, time elapse for current epoch: 102.1304018497467\n",
      "Epoch: 87, Test set ELBO: 24.003971099853516, time elapse for current epoch: 101.70601105690002\n",
      "Epoch: 88, Test set ELBO: 23.987707138061523, time elapse for current epoch: 101.26092529296875\n",
      "Epoch: 89, Test set ELBO: 23.993452072143555, time elapse for current epoch: 98.33648133277893\n",
      "Epoch: 90, Test set ELBO: 23.989727020263672, time elapse for current epoch: 106.16092872619629\n",
      "Epoch: 91, Test set ELBO: 23.994789123535156, time elapse for current epoch: 102.61711955070496\n",
      "Epoch: 92, Test set ELBO: 24.01376724243164, time elapse for current epoch: 102.76458764076233\n",
      "Epoch: 93, Test set ELBO: 23.987014770507812, time elapse for current epoch: 118.43388223648071\n",
      "Epoch: 94, Test set ELBO: 23.995973587036133, time elapse for current epoch: 112.03223752975464\n",
      "Epoch: 95, Test set ELBO: 23.991374969482422, time elapse for current epoch: 99.1886932849884\n",
      "Epoch: 96, Test set ELBO: 23.984912872314453, time elapse for current epoch: 104.24246215820312\n",
      "Epoch: 97, Test set ELBO: 24.04098129272461, time elapse for current epoch: 96.14449191093445\n",
      "Epoch: 98, Test set ELBO: 24.006847381591797, time elapse for current epoch: 91.47815990447998\n",
      "Epoch: 99, Test set ELBO: 23.979482650756836, time elapse for current epoch: 93.73349857330322\n",
      "Epoch: 100, Test set ELBO: 23.9931640625, time elapse for current epoch: 92.26686406135559\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "        train_step(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test_dataset:\n",
    "        loss(compute_loss(model, test_x))\n",
    "\n",
    "    elbo = loss.result()\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c205e7-d777-46ac-9a35-cd5bb4fa2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"01\"\n",
    "model.encoder.save_weights('./Weights/cnn_vae_v' + ae_version + '_encoder_weights_' + version)\n",
    "model.decoder.save_weights('./Weights/cnn_vae_v' + ae_version + '_decoder_weights_' + version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc6e5684-1126-4ae5-a254-4ca7c64aca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    return x_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d3796f1-621a-41da-8884-adb3f60e7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = predict(model,datacube_precip[:10,:,:,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25b9828a-85b7-42e7-9177-e13b64172cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./Testing/temp_CVAE_v\" +version+ \".npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2787b38-38d9-490b-bd55-0ff35069db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_test(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    #Reconstruction loss\n",
    "    reconstruction_loss = tf.keras.backend.mean(tf.math.square(x_logit - x[:,1:181,1:361,:]), axis=[1, 2, 3])\n",
    "    #KL div loss\n",
    "    kl_loss = - 0.5 * tf.keras.backend.mean(1 + logvar - tf.keras.backend.square(mean) - tf.keras.backend.exp(logvar), axis=-1)\n",
    "    elbo = tf.keras.backend.mean(reconstruction_loss + kl_loss)\n",
    "    test = tf.keras.backend.mean(tf.math.square(x_logit - x[:,1:181,1:361,:]), axis=[1, 2, 3])\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28d1b9a1-0e4b-4b0d-ba47-d7180e31bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([30.622057, 27.244976, 26.310926, 24.937326, 27.256582, 26.601446,\n",
       "       28.952744, 29.623966, 23.67386 , 21.789776], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = fun_test(model,datacube_precip[:10,:,:,:] )\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bd4e6-cd8d-4b48-b64a-ba452b3c297d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176d91e-f8c9-4e89-87ff-03807d566f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
