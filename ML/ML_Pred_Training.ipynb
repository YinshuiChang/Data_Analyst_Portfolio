{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f138b62-acb5-4537-b98c-fb87cda1e401",
   "metadata": {},
   "source": [
    "# A CNN predictor using the latent layer of a Convolutional Autoencoder (CAE) \n",
    "A neural network architecture where the compressed representation (latent layer) generated by a CAE is used as input for a Convolutional Neural Network (CNN) designed for prediction tasks, such as classification or regression. This approach leverages the CAE's ability to distill essential features from the input data, enhancing the performance of the subsequent prediction model.\n",
    "## Architecture:\n",
    "Outline of the combined architecture:\n",
    "+ **CAE Encoder:** Input Image -> Convolutional Layers  -> Latent Space\n",
    "+ **Latent Space Representation:** Pooling the Latent Space Layers\n",
    "+ **CNN Predictor:** Latent Space -> Deconvolutional Layers -> Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547031cf-a097-4db7-a7b2-8115ee5838f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "from Models import CNN_pred_MMUMM_v01 as pcnn\n",
    "cnn_slayers = pcnn.slayers\n",
    "cnn_nlayers = pcnn.nlayers\n",
    "cnn_version = pcnn.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b126ccc9-5a7f-4fba-aa0e-200b5fbb0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.9\n",
      "numpy: 1.23.5\n",
      "tensorflow: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import sys\n",
    "print('Python: ' + python_version()) # Python: 3.10.9\n",
    "print('numpy: ' + np.__version__) # numpy: 1.23.5\n",
    "print ('tensorflow: ' + sys.modules[\"tensorflow\"].__version__) # tensorflow: 2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1a34506-1019-46e5-9eb0-3a1e23aeaa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([[[[100]]*360]*50 + [[[0]]*360]*80 + [[[100]]*360]*50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52c36241-cbf7-442c-9ac2-e408e24cb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(true, pred):\n",
    "    error = tf.math.reduce_mean(tf.math.square(true - pred)* mask)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9085391-18e4-4163-b05d-3a667eae86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = CNN_pred()\n",
    "cnn = pcnn.CNN_pred()\n",
    "# cnn.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "cnn.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2250ab1-9e74-4dbe-adb8-e563e1e06e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_transpose_16 (Conv2D  (None, 45, 90, 8)        368       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_17 (Conv2D  (None, 90, 180, 16)      1168      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_18 (Conv2D  (None, 90, 180, 16)      2320      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_19 (Conv2D  (None, 180, 360, 8)      1160      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 180, 360, 1)       129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,145\n",
      "Trainable params: 5,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.build((None,45, 90, cnn_nlayers))\n",
    "cnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf697e5-3239-425a-b716-2a06c94064ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"01\"\n",
    "cnn = pcnn.CNN_pred()\n",
    "cnn.model.load_weights('./Weights/cnn_pred_' + cnn_slayers + '_v' + cnn_version + '_weights_' + version)\n",
    "cnn.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "cnn.build((None,45, 90, cnn_nlayers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a9968b2-2ab3-4bf6-96c1-e0777a60124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_precip_x = np.load(\"../data/WaterPrecip_datacube_CNN_x_encoded.npy\")\n",
    "data_precip_x = np.load(\"../data/WaterPrecip_datacube_CNN_x_encoded_singles_masked.npy\")\n",
    "data_precip_y = np.load(\"../data/WaterPrecip_datacube_CNN_y_s2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e37c0fbe-29c8-4e31-b3e7-de35f9ddb4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8826, 45, 90, 5)\n",
      "(8826, 180, 360, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data_precip_x.shape)\n",
    "print(data_precip_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "536a0387-3d7a-4ace-884b-7da0062f61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTest = 1000\n",
    "iTest = np.random.choice(data_precip_x.shape[0],nTest, replace=False)\n",
    "iTrain = [i for i in range(data_precip_x.shape[0]) if i not in iTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3ea18da-dad9-42ed-86e4-b53d78484ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 [==============================] - 66s 267ms/step - loss: 629.1845 - val_loss: 604.9081\n",
      "Epoch 2/10\n",
      "245/245 [==============================] - 70s 286ms/step - loss: 591.9406 - val_loss: 586.1635\n",
      "Epoch 3/10\n",
      "245/245 [==============================] - 62s 251ms/step - loss: 580.6876 - val_loss: 577.8719\n",
      "Epoch 4/10\n",
      "245/245 [==============================] - 67s 274ms/step - loss: 576.1962 - val_loss: 576.6320\n",
      "Epoch 5/10\n",
      "245/245 [==============================] - 63s 256ms/step - loss: 573.8033 - val_loss: 573.8113\n",
      "Epoch 6/10\n",
      "245/245 [==============================] - 69s 282ms/step - loss: 571.7773 - val_loss: 572.2648\n",
      "Epoch 7/10\n",
      "245/245 [==============================] - 71s 289ms/step - loss: 570.7818 - val_loss: 571.0503\n",
      "Epoch 8/10\n",
      "245/245 [==============================] - 68s 277ms/step - loss: 569.8599 - val_loss: 569.7554\n",
      "Epoch 9/10\n",
      "245/245 [==============================] - 61s 250ms/step - loss: 568.6092 - val_loss: 568.3555\n",
      "Epoch 10/10\n",
      "245/245 [==============================] - 63s 259ms/step - loss: 568.2516 - val_loss: 568.4938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c1b2f9690>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(data_precip_x[iTrain][:,:,:,[0,1,2,3,4]], data_precip_y[iTrain,:,:,:],\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(data_precip_x[iTest][:,:,:,[0,1,2,3,4]], data_precip_y[iTest,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8184d41-f119-4d6a-a4af-bc15dbd588c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"02\"\n",
    "cnn.model.save_weights('./Weights/cnn_pred_' + cnn_slayers + '_v' + cnn_version + '_weights_' + version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5aa1a-571e-40b8-8400-55a07bf2eca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
